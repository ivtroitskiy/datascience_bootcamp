{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Над этим проектом нужно будет еще немного поработать. Однако, изменения не должны занять много времени.\n",
    "* С радостью отвечу на твои вопросы, если они есть. Лучше всего их собрать в следующей ячейке. Жду новую версию проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> \n",
    "Артем, привет! Я не знаю как так произошло, но загрузилась неполная версия проекта :( Прошу прощения!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> \n",
    "Я пробовал запусукать вычилсения на GPU, но у меня не получилось. Ошибка: данные и модель на разных устройствах. Как перекинуть даныне на GPU, я не разобрался, пример из туторила `Data.to(device)` не сработал\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Для удобства все новые комментарии обозначены фразой \"ревью 2\".\n",
    "* Удачи в доработке!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 3)</font>\n",
    "* После исправлений проект улучшился и теперь он может быть зачтен.\n",
    "* Удачи в дальнейшем обучении и следующих работах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дата: 25 июля 2023  \n",
    "Исполнитель: Троицкий Илья  \n",
    "Проект выполнен в рамках курса Datascience Bootcamp  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-3)\" data-toc-modified-id=\"Общее-впечатление-(ревью-3)-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 3)</font></a></span></li></ul></li><li><span><a href=\"#Описание-проекта\" data-toc-modified-id=\"Описание-проекта-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Описание проекта</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-на-тестовых-данных\" data-toc-modified-id=\"Проверка-на-тестовых-данных-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Проверка на тестовых данных</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT_MODEL = 'prajjwal1/bert-tiny' # Каталог с пре-тренированной моделью BERT\n",
    "BERT_MODEL = 'unitary/toxic-bert' # указать distilbert есть будем работать с моделью из библиотеки transformers\n",
    "\n",
    "SAMPLE_SIZE = 1000 # количество элементов в выборке \n",
    "BATCH_SIZE = 100 # Размер батча для формирования эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0ca48967f0472b9f43b2fc3902749a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/811 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ae89ee53904eb5aa950ab745f93c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd610635f61a4d54a5ecc337c3580e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8fa78376b54013b7950f8d418bb171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893b66fdd2d4a8594e7fb7b522c5884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружена модель unitary/toxic-bert.\n"
     ]
    }
   ],
   "source": [
    "if (BERT_MODEL == 'distilbert'):\n",
    "    model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel,\n",
    "                                                        transformers.DistilBertTokenizer,\n",
    "                                                        'distilbert-base-uncased')\n",
    "\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "    print('Загружена модель Distilbert')\n",
    "elif (BERT_MODEL == 'prajjwal1/bert-tiny'):\n",
    "    model = transformers.BertModel.from_pretrained(BERT_MODEL)\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    print(f'Загружена модель {BERT_MODEL}.')  \n",
    "elif (BERT_MODEL == 'unitary/toxic-bert'):\n",
    "    model = transformers.BertModel.from_pretrained(BERT_MODEL)\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    print(f'Загружена модель {BERT_MODEL}.')       \n",
    "else:    \n",
    "    model = transformers.BertModel.from_pretrained(BERT_MODEL)\n",
    "    tokenizer = transformers.BertTokenizerFast(vocab_file='{}/vocab.txt'.format(BERT_MODEL))\n",
    "    print(f'Загружена модель {BERT_MODEL}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно загружены.\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('/datasets')):\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "elif (os.path.exists('datasets')):\n",
    "    df = pd.read_csv('datasets/toxic_comments.csv')\n",
    "elif os.path.exists('toxic_comments.csv'):\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "else:    \n",
    "    raise Exception('Не найден файл с данными.')    \n",
    "\n",
    "print('Данные успешно загружены.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрит какой длины текст бывает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159292.000000\n",
       "mean        393.691303\n",
       "std         590.111825\n",
       "min           5.000000\n",
       "25%          95.000000\n",
       "50%         205.000000\n",
       "75%         435.000000\n",
       "max        5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = df.text.map(len)\n",
    "text_len.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не придумал, как выбросить тексты, которые после токенизации имеют больше допустимого количества токенов, поэтому отсек все тексты длинне 512 символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126276, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_LIMIT = 512\n",
    "df = df[text_len < TOKENS_LIMIT]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.887896\n",
       "1    0.112104\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных находится 159292 коммента. Удалили столбец с номером строки. Очистили данные от аномально больших текстов, теперь самый длинный текст короче 1001 символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.892\n",
       "1    0.108\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.sample(SAMPLE_SIZE).reset_index(drop=True)\n",
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. Радует, что баланс классов был изучен.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Уменьшить объем данных – хорошая идея!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представление ошибки, если по какому то тексту, будет сформировано большое количество токенов. \n",
    "\n",
    "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 780 ms, sys: 0 ns, total: 780 ms\n",
      "Wall time: 787 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized = data['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что получилось на первом элементе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: cant help acting like a little punk ass bitch\n",
      "len: 45\n",
      "tokens: [101, 2064, 2102, 2393, 3772, 2066, 1037, 2210, 7196, 4632, 7743, 102]\n",
      "len:  12\n"
     ]
    }
   ],
   "source": [
    "print('text:', data['text'][0])\n",
    "print('len:', len(data['text'][0]))\n",
    "print('tokens:', tokenized[0])\n",
    "print('len: ', len(tokenized[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем максимальную длину списка токенов, заодно посмотри что за текст имеет столько токенов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"And the modern examples now are supported:\n",
      "\n",
      "+ Numbers           0 1 2 3 4 5 6 7 8 9\n",
      "    \n",
      "{| class=\"\"wikitable\"\" style=\"\"text-align:center;\"\"\n",
      "|+ Latin alphabet\n",
      "|-\n",
      "|      \n",
      "|   \n",
      "|  \n",
      "|   \n",
      "|  \n",
      "| \n",
      "|  \n",
      "|  \n",
      "|  \n",
      "|-\n",
      "| A, a; @\n",
      "| B, b\n",
      "| C, c\n",
      "| D, d\n",
      "| E, e\n",
      "| F, f\n",
      "| G, g\n",
      "| H, h\n",
      "| I, i\n",
      "|-\n",
      "|    \n",
      "|     \n",
      "|    \n",
      "|     \n",
      "|    \n",
      "| \n",
      "|  \n",
      "| \n",
      "|  \n",
      "|-\n",
      "| J, j\n",
      "| K, k\n",
      "| L, l\n",
      "| M, m\n",
      "| N, n\n",
      "| Ñ, ñ\n",
      "| O, o\n",
      "| P, p\n",
      "| Q, q\n",
      "|-\n",
      "|   \n",
      "|   \n",
      "|    \n",
      "|  \n",
      "|    \n",
      "|     \n",
      "|  \n",
      "|    \n",
      "|   \n",
      "|-\n",
      "| R, r\n",
      "| [[S|S, s\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "y = 0\n",
    "max_len_index = 0\n",
    "\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        max_i = y\n",
    "    y += 1    \n",
    "\n",
    "print(data['text'][max_i])\n",
    "print(max_len)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тексте, с самым большим вектором токеном содержится огромное количество занков препинания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем все векторы одинакого размера и составим маску внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим эмбеденнги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce8d687afee47cb95cccc0b4df29950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 10s, sys: 2min 46s, total: 12min 57s\n",
      "Wall time: 12min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // BATCH_SIZE)):\n",
    "        batch = torch.LongTensor(padded[BATCH_SIZE*i:BATCH_SIZE*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[BATCH_SIZE*i:BATCH_SIZE*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что освоил и применил векторизацию с помощью БЕРТа!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим фичи и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=31337, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1:  0.9599999999999999\n",
      "CPU times: user 2.86 s, sys: 3.34 s, total: 6.21 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "param_grid = {'C': [0.1, 0.5, 1, 5, 10] }\n",
    "\n",
    "\n",
    "est = LogisticRegression(max_iter = 10000, random_state = 31337)\n",
    "clf = GridSearchCV(est, \n",
    "                   cv=5, \n",
    "                   scoring='f1', \n",
    "                   param_grid=param_grid,\n",
    "                   n_jobs=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "LR_model = clf.best_estimator_\n",
    "print('Logistic Regression F1: ', f1_score(y_train, LR_model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tloss: 0.0195424\tbest: 0.0195424 (0)\ttotal: 11.2s\tremaining: 2m 2s\n",
      "1:\tloss: 0.1574029\tbest: 0.0195424 (0)\ttotal: 22.2s\tremaining: 1m 51s\n",
      "2:\tloss: 0.0182823\tbest: 0.0182823 (2)\ttotal: 43.5s\tremaining: 2m 10s\n",
      "3:\tloss: 0.0553086\tbest: 0.0182823 (2)\ttotal: 1m 4s\tremaining: 2m 9s\n",
      "4:\tloss: 0.0161646\tbest: 0.0161646 (4)\ttotal: 1m 37s\tremaining: 2m 15s\n",
      "5:\tloss: 0.0300551\tbest: 0.0161646 (4)\ttotal: 2m 8s\tremaining: 2m 8s\n",
      "Estimating final quality...\n",
      "CatBoost F1 score: {'learn': {'F1': 1.0, 'Logloss': 0.0007646241480924183}}\n",
      "CPU times: user 4min 7s, sys: 6.62 s, total: 4min 14s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "cat = CatBoostClassifier(random_seed=31337,\n",
    "                          iterations=500,\n",
    "                          custom_metric='F1',\n",
    "                          logging_level='Silent',\n",
    "                          )\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 127],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid_search_result = cat.grid_search(param_grid,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            cv=3,\n",
    "            partition_random_seed=31337,\n",
    "            calc_cv_statistics=True,\n",
    "            search_by_train_test_split=True,\n",
    "            refit=True,\n",
    "            shuffle=True,\n",
    "            stratified=None,\n",
    "            train_size=0.8,\n",
    "            verbose=True,\n",
    "            plot=False,\n",
    "            )\n",
    "            \n",
    "print('CatBoost F1 score:', cat.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaves': 31, 'iterations': 150, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f13d67cc1f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search_result['params'])\n",
    "\n",
    "\n",
    "CB_model = CatBoostClassifier(**grid_search_result['params'], \n",
    "                              random_seed=31337, \n",
    "                              logging_level='Silent')\n",
    "CB_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ради интереса, возьмем модет CatBoost с вручную заданными метапараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn': {'Logloss': 0.0015241264592813152, 'F1': 1.0}}\n",
      "CPU times: user 1min 44s, sys: 1.1 s, total: 1min 45s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "cb_manual = CatBoostClassifier(eval_metric='F1',\n",
    "                        random_seed=31337,\n",
    "                        logging_level='Silent',\n",
    "                        iterations=500,\n",
    "                        od_type='Iter',\n",
    "                        od_wait=500)\n",
    "cb_manual.fit(X_train,y_train)\n",
    "print(cb_manual.get_best_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данных обучения, лучшую оценку показываеть модель CatBoost, полученная с помощью перебора метапараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CB_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model F1 score: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "print('best_model F1 score:', f1_score(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, scoring='f1')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Ошибка:</b> На тестовой выборке нужно измерить только одну – лучшую модель. Сравнение моделей нужно провести только на кросс-валидации `grid.best_score_` (с одним и тем же параметром \"cv\") или только на валидационной выборке.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Ошибка:</b> Для улучшения качества можно использовать специализированный берт: https://huggingface.co/unitary/toxic-bert\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> \n",
    "Попробовал, тренажер с этой моделью умирает\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка (ревью 2):</b> Можешь тогда попробовать уменьшить выборку или попробовать подход с tfidf. Требуемое качество у тебя не достигнуто, проект не может быть зачтен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента v2:</b> \n",
    "best_model F1 score: 0.9333333333333332\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете представлены тексты комментариев и содержиться целевой признак  `toxic`. Данные очищены от лишней информации. Произведено превращение текста в токены и последуюшая ембедизация с помощью пред-обученной модели BERT-tiny. На получившихся признаках обучены модели логистической регрессии и CatBoost. В процессе обуения CatBoost показала лучший результат, поэтому она выбирается как финальная. На тестовых данных результаты выше, чем у искуственной модели. Использую предобученную модель bert-toxic удалось достичь оценки F1 0.93, что выше требуемой по ТЗ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 73,
    "start_time": "2023-08-04T02:17:28.084Z"
   },
   {
    "duration": 66,
    "start_time": "2023-08-04T02:20:30.973Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-04T02:21:36.046Z"
   },
   {
    "duration": 65,
    "start_time": "2023-08-04T02:23:00.039Z"
   },
   {
    "duration": 65,
    "start_time": "2023-08-04T02:23:08.799Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-04T02:24:00.272Z"
   },
   {
    "duration": 80,
    "start_time": "2023-08-04T02:25:29.739Z"
   },
   {
    "duration": 900,
    "start_time": "2023-08-04T02:28:05.721Z"
   },
   {
    "duration": 60,
    "start_time": "2023-08-04T02:28:14.243Z"
   },
   {
    "duration": 2715,
    "start_time": "2023-08-04T02:28:28.177Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T02:28:30.894Z"
   },
   {
    "duration": 50,
    "start_time": "2023-08-04T02:28:30.899Z"
   },
   {
    "duration": 2258,
    "start_time": "2023-08-04T02:28:30.951Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.212Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.213Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.214Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.215Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.216Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.217Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.218Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.219Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.220Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.221Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.221Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.222Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.223Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.224Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.225Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.226Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.228Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.228Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.229Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T02:28:33.230Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T02:33:58.990Z"
   },
   {
    "duration": 2431,
    "start_time": "2023-08-04T02:34:01.078Z"
   },
   {
    "duration": 795,
    "start_time": "2023-08-04T02:39:10.637Z"
   },
   {
    "duration": 866,
    "start_time": "2023-08-04T02:41:09.039Z"
   },
   {
    "duration": 3172,
    "start_time": "2023-08-04T02:41:51.059Z"
   },
   {
    "duration": 980,
    "start_time": "2023-08-04T02:42:43.004Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T02:43:02.740Z"
   },
   {
    "duration": 3704,
    "start_time": "2023-08-04T02:43:07.781Z"
   },
   {
    "duration": 3200,
    "start_time": "2023-08-04T02:43:18.030Z"
   },
   {
    "duration": 783,
    "start_time": "2023-08-04T02:43:32.129Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T02:43:38.057Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-04T02:43:38.062Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-04T02:43:38.088Z"
   },
   {
    "duration": 3402,
    "start_time": "2023-08-04T02:43:38.107Z"
   },
   {
    "duration": 750,
    "start_time": "2023-08-04T02:43:41.511Z"
   },
   {
    "duration": 779,
    "start_time": "2023-08-04T02:43:48.944Z"
   },
   {
    "duration": 37,
    "start_time": "2023-08-04T02:43:49.725Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T02:43:49.775Z"
   },
   {
    "duration": 69,
    "start_time": "2023-08-04T02:43:49.793Z"
   },
   {
    "duration": 127,
    "start_time": "2023-08-04T02:43:49.864Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T02:43:49.993Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T02:43:50.007Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-04T02:43:50.014Z"
   },
   {
    "duration": 708,
    "start_time": "2023-08-04T02:43:50.028Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T02:43:50.738Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-04T02:43:50.744Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-04T02:43:50.753Z"
   },
   {
    "duration": 5597,
    "start_time": "2023-08-04T02:43:50.792Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T02:43:56.391Z"
   },
   {
    "duration": 8577,
    "start_time": "2023-08-04T02:43:56.398Z"
   },
   {
    "duration": 30962,
    "start_time": "2023-08-04T02:44:04.982Z"
   },
   {
    "duration": 3424,
    "start_time": "2023-08-04T02:44:35.946Z"
   },
   {
    "duration": 3014,
    "start_time": "2023-08-04T02:46:28.833Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-04T02:46:31.849Z"
   },
   {
    "duration": 25,
    "start_time": "2023-08-04T02:46:31.853Z"
   },
   {
    "duration": 4886,
    "start_time": "2023-08-04T02:46:31.880Z"
   },
   {
    "duration": 783,
    "start_time": "2023-08-04T02:46:36.768Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-04T02:46:37.552Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-04T02:46:37.593Z"
   },
   {
    "duration": 77,
    "start_time": "2023-08-04T02:46:37.610Z"
   },
   {
    "duration": 124,
    "start_time": "2023-08-04T02:46:37.688Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T02:46:37.813Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T02:46:37.827Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-04T02:46:37.834Z"
   },
   {
    "duration": 649,
    "start_time": "2023-08-04T02:46:37.844Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T02:46:38.496Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-04T02:46:38.501Z"
   },
   {
    "duration": 26,
    "start_time": "2023-08-04T02:46:38.512Z"
   },
   {
    "duration": 12452,
    "start_time": "2023-08-04T02:46:38.540Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T02:46:50.993Z"
   },
   {
    "duration": 8676,
    "start_time": "2023-08-04T02:46:51.000Z"
   },
   {
    "duration": 36890,
    "start_time": "2023-08-04T02:46:59.679Z"
   },
   {
    "duration": 4926,
    "start_time": "2023-08-04T02:47:36.571Z"
   },
   {
    "duration": 149518,
    "start_time": "2023-08-04T02:47:41.499Z"
   },
   {
    "duration": 62,
    "start_time": "2023-08-04T02:50:11.019Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-04T02:50:11.174Z"
   },
   {
    "duration": 2772,
    "start_time": "2023-08-04T02:59:36.162Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-04T02:59:38.936Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T02:59:38.940Z"
   },
   {
    "duration": 6705,
    "start_time": "2023-08-04T02:59:38.946Z"
   },
   {
    "duration": 790,
    "start_time": "2023-08-04T02:59:45.652Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-04T02:59:46.444Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T02:59:46.481Z"
   },
   {
    "duration": 77,
    "start_time": "2023-08-04T02:59:46.498Z"
   },
   {
    "duration": 126,
    "start_time": "2023-08-04T02:59:46.576Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T02:59:46.705Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T02:59:46.719Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-04T02:59:46.727Z"
   },
   {
    "duration": 639,
    "start_time": "2023-08-04T02:59:46.736Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T02:59:47.377Z"
   },
   {
    "duration": 23,
    "start_time": "2023-08-04T02:59:47.382Z"
   },
   {
    "duration": 23,
    "start_time": "2023-08-04T02:59:47.406Z"
   },
   {
    "duration": 6848,
    "start_time": "2023-08-04T02:59:47.430Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T02:59:54.279Z"
   },
   {
    "duration": 8989,
    "start_time": "2023-08-04T02:59:54.286Z"
   },
   {
    "duration": 32241,
    "start_time": "2023-08-04T03:00:03.278Z"
   },
   {
    "duration": 5897,
    "start_time": "2023-08-04T03:00:35.521Z"
   },
   {
    "duration": 2781,
    "start_time": "2023-08-04T03:02:20.596Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:02:23.380Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-04T03:02:23.385Z"
   },
   {
    "duration": 5268,
    "start_time": "2023-08-04T03:02:23.404Z"
   },
   {
    "duration": 780,
    "start_time": "2023-08-04T03:02:28.675Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-04T03:02:29.457Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T03:02:29.494Z"
   },
   {
    "duration": 86,
    "start_time": "2023-08-04T03:02:29.512Z"
   },
   {
    "duration": 127,
    "start_time": "2023-08-04T03:02:29.599Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T03:02:29.727Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T03:02:29.742Z"
   },
   {
    "duration": 51,
    "start_time": "2023-08-04T03:02:29.759Z"
   },
   {
    "duration": 802,
    "start_time": "2023-08-04T03:02:29.811Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:02:30.615Z"
   },
   {
    "duration": 64,
    "start_time": "2023-08-04T03:02:30.622Z"
   },
   {
    "duration": 54,
    "start_time": "2023-08-04T03:02:30.688Z"
   },
   {
    "duration": 5252,
    "start_time": "2023-08-04T03:02:30.743Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:02:35.997Z"
   },
   {
    "duration": 8572,
    "start_time": "2023-08-04T03:02:36.003Z"
   },
   {
    "duration": 38356,
    "start_time": "2023-08-04T03:02:44.578Z"
   },
   {
    "duration": 5290,
    "start_time": "2023-08-04T03:03:22.937Z"
   },
   {
    "duration": 16402,
    "start_time": "2023-08-04T03:03:28.229Z"
   },
   {
    "duration": 130,
    "start_time": "2023-08-04T03:03:44.633Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:03:44.765Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:03:44.766Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:04:28.993Z"
   },
   {
    "duration": 476,
    "start_time": "2023-08-04T03:04:40.585Z"
   },
   {
    "duration": 82,
    "start_time": "2023-08-04T03:04:45.794Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T03:05:27.729Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:05:31.257Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T03:05:38.211Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T03:05:53.010Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T03:05:55.762Z"
   },
   {
    "duration": 5358,
    "start_time": "2023-08-04T03:06:55.046Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T03:07:00.407Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-04T03:07:00.412Z"
   },
   {
    "duration": 6959,
    "start_time": "2023-08-04T03:07:00.463Z"
   },
   {
    "duration": 864,
    "start_time": "2023-08-04T03:07:07.424Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-04T03:07:08.290Z"
   },
   {
    "duration": 61,
    "start_time": "2023-08-04T03:07:08.328Z"
   },
   {
    "duration": 98,
    "start_time": "2023-08-04T03:07:08.391Z"
   },
   {
    "duration": 163,
    "start_time": "2023-08-04T03:07:08.492Z"
   },
   {
    "duration": 34,
    "start_time": "2023-08-04T03:07:08.657Z"
   },
   {
    "duration": 27,
    "start_time": "2023-08-04T03:07:08.692Z"
   },
   {
    "duration": 42,
    "start_time": "2023-08-04T03:07:08.721Z"
   },
   {
    "duration": 6526,
    "start_time": "2023-08-04T03:07:08.764Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:07:15.293Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-04T03:07:15.299Z"
   },
   {
    "duration": 392,
    "start_time": "2023-08-04T03:07:15.316Z"
   },
   {
    "duration": 100711,
    "start_time": "2023-08-04T03:07:15.710Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-04T03:08:56.424Z"
   },
   {
    "duration": 34841,
    "start_time": "2023-08-04T03:08:56.437Z"
   },
   {
    "duration": 3210,
    "start_time": "2023-08-04T03:09:41.223Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-04T03:09:44.435Z"
   },
   {
    "duration": 34,
    "start_time": "2023-08-04T03:09:44.439Z"
   },
   {
    "duration": 5258,
    "start_time": "2023-08-04T03:09:44.475Z"
   },
   {
    "duration": 887,
    "start_time": "2023-08-04T03:09:49.735Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-04T03:09:50.624Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-04T03:09:50.662Z"
   },
   {
    "duration": 86,
    "start_time": "2023-08-04T03:09:50.688Z"
   },
   {
    "duration": 130,
    "start_time": "2023-08-04T03:09:50.776Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T03:09:50.909Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:09:50.924Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-04T03:09:50.931Z"
   },
   {
    "duration": 32552,
    "start_time": "2023-08-04T03:09:50.960Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:10:23.514Z"
   },
   {
    "duration": 45,
    "start_time": "2023-08-04T03:10:23.521Z"
   },
   {
    "duration": 1797,
    "start_time": "2023-08-04T03:10:23.568Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-04T03:17:18.009Z"
   },
   {
    "duration": 2874,
    "start_time": "2023-08-04T03:17:31.983Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:17:34.859Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-04T03:17:34.863Z"
   },
   {
    "duration": 5722,
    "start_time": "2023-08-04T03:17:34.877Z"
   },
   {
    "duration": 3158,
    "start_time": "2023-08-04T03:17:40.601Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-04T03:17:43.762Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-04T03:17:43.802Z"
   },
   {
    "duration": 83,
    "start_time": "2023-08-04T03:17:43.822Z"
   },
   {
    "duration": 131,
    "start_time": "2023-08-04T03:17:43.907Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-04T03:17:44.040Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T03:17:44.053Z"
   },
   {
    "duration": 26,
    "start_time": "2023-08-04T03:17:44.060Z"
   },
   {
    "duration": 6533,
    "start_time": "2023-08-04T03:17:44.087Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:17:50.622Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-04T03:17:50.628Z"
   },
   {
    "duration": 356,
    "start_time": "2023-08-04T03:17:50.638Z"
   },
   {
    "duration": 91013,
    "start_time": "2023-08-04T03:17:50.996Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-04T03:19:22.011Z"
   },
   {
    "duration": 35852,
    "start_time": "2023-08-04T03:19:22.026Z"
   },
   {
    "duration": 40900,
    "start_time": "2023-08-04T03:19:57.881Z"
   },
   {
    "duration": 287,
    "start_time": "2023-08-04T03:20:38.782Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:20:39.074Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:20:39.075Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:20:39.076Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:20:39.077Z"
   },
   {
    "duration": 6170,
    "start_time": "2023-08-04T03:22:49.356Z"
   },
   {
    "duration": 19223,
    "start_time": "2023-08-04T03:23:05.493Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:23:27.668Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-04T03:23:33.589Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-04T03:23:34.924Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:24:33.534Z"
   },
   {
    "duration": 1390,
    "start_time": "2023-08-04T03:24:35.374Z"
   },
   {
    "duration": 3804,
    "start_time": "2023-08-04T03:25:20.111Z"
   },
   {
    "duration": 14864,
    "start_time": "2023-08-04T03:25:49.023Z"
   },
   {
    "duration": 3986,
    "start_time": "2023-08-04T03:26:14.856Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:26:18.844Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-04T03:26:18.848Z"
   },
   {
    "duration": 7446,
    "start_time": "2023-08-04T03:26:18.873Z"
   },
   {
    "duration": 738,
    "start_time": "2023-08-04T03:26:26.321Z"
   },
   {
    "duration": 487,
    "start_time": "2023-08-04T03:26:27.061Z"
   },
   {
    "duration": 3370,
    "start_time": "2023-08-04T03:26:27.550Z"
   },
   {
    "duration": 428,
    "start_time": "2023-08-04T03:26:30.921Z"
   },
   {
    "duration": 127,
    "start_time": "2023-08-04T03:26:31.351Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-04T03:26:31.479Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-04T03:26:31.494Z"
   },
   {
    "duration": 74,
    "start_time": "2023-08-04T03:26:31.509Z"
   },
   {
    "duration": 6840,
    "start_time": "2023-08-04T03:26:31.585Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T03:26:38.429Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-04T03:26:38.435Z"
   },
   {
    "duration": 400,
    "start_time": "2023-08-04T03:26:38.451Z"
   },
   {
    "duration": 3749,
    "start_time": "2023-08-04T03:28:23.584Z"
   },
   {
    "duration": 2,
    "start_time": "2023-08-04T03:28:27.335Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-04T03:28:27.339Z"
   },
   {
    "duration": 173,
    "start_time": "2023-08-04T03:28:27.347Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.522Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.523Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.524Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.525Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.526Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.527Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.528Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.530Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.531Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.531Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.533Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.534Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.535Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.536Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.537Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.538Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.539Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.540Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.541Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.542Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-04T03:28:27.574Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:28:48.837Z"
   },
   {
    "duration": 3426,
    "start_time": "2023-08-04T03:28:58.954Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:29:02.384Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-04T03:29:02.391Z"
   },
   {
    "duration": 5616,
    "start_time": "2023-08-04T03:29:02.403Z"
   },
   {
    "duration": 3350,
    "start_time": "2023-08-04T03:29:08.021Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-04T03:29:11.373Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-04T03:29:11.416Z"
   },
   {
    "duration": 91,
    "start_time": "2023-08-04T03:29:11.432Z"
   },
   {
    "duration": 134,
    "start_time": "2023-08-04T03:29:11.525Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-04T03:29:11.661Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-04T03:29:11.692Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-04T03:29:11.701Z"
   },
   {
    "duration": 6754,
    "start_time": "2023-08-04T03:29:11.713Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-04T03:29:18.470Z"
   },
   {
    "duration": 27,
    "start_time": "2023-08-04T03:29:18.478Z"
   },
   {
    "duration": 482,
    "start_time": "2023-08-04T03:29:18.507Z"
   },
   {
    "duration": 3588,
    "start_time": "2023-08-04T03:39:06.216Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:39:09.806Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-04T03:39:09.811Z"
   },
   {
    "duration": 5638,
    "start_time": "2023-08-04T03:39:09.818Z"
   },
   {
    "duration": 3427,
    "start_time": "2023-08-04T03:39:15.457Z"
   },
   {
    "duration": 45,
    "start_time": "2023-08-04T03:39:18.887Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-04T03:39:18.934Z"
   },
   {
    "duration": 90,
    "start_time": "2023-08-04T03:39:18.952Z"
   },
   {
    "duration": 161,
    "start_time": "2023-08-04T03:39:19.043Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-04T03:39:19.207Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-04T03:39:19.221Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-04T03:39:19.250Z"
   },
   {
    "duration": 772,
    "start_time": "2023-08-04T03:39:19.284Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-04T03:39:20.057Z"
   },
   {
    "duration": 46,
    "start_time": "2023-08-04T03:39:20.062Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-04T03:39:20.110Z"
   },
   {
    "duration": 6861,
    "start_time": "2023-08-04T03:39:20.136Z"
   },
   {
    "duration": 76,
    "start_time": "2023-08-04T03:39:26.999Z"
   },
   {
    "duration": 14603,
    "start_time": "2023-08-04T03:39:27.077Z"
   },
   {
    "duration": 36204,
    "start_time": "2023-08-04T03:39:41.683Z"
   },
   {
    "duration": 4636,
    "start_time": "2023-08-04T03:40:17.889Z"
   },
   {
    "duration": 18274,
    "start_time": "2023-08-04T03:40:22.527Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-04T03:40:40.802Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-04T03:40:40.807Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-04T03:40:40.819Z"
   },
   {
    "duration": 3038,
    "start_time": "2023-08-05T10:02:17.280Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-05T10:02:20.321Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-05T10:02:20.327Z"
   },
   {
    "duration": 16087,
    "start_time": "2023-08-05T10:02:20.348Z"
   },
   {
    "duration": 2742,
    "start_time": "2023-08-05T10:02:36.439Z"
   },
   {
    "duration": 44,
    "start_time": "2023-08-05T10:02:39.183Z"
   },
   {
    "duration": 27,
    "start_time": "2023-08-05T10:02:39.229Z"
   },
   {
    "duration": 82,
    "start_time": "2023-08-05T10:02:39.258Z"
   },
   {
    "duration": 133,
    "start_time": "2023-08-05T10:02:39.342Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-05T10:02:39.477Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-05T10:02:39.509Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-05T10:02:39.517Z"
   },
   {
    "duration": 791,
    "start_time": "2023-08-05T10:02:39.538Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-05T10:02:40.333Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-05T10:02:40.341Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-05T10:02:40.351Z"
   },
   {
    "duration": 777439,
    "start_time": "2023-08-05T10:02:40.396Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-05T10:15:37.837Z"
   },
   {
    "duration": 16485,
    "start_time": "2023-08-05T10:15:37.848Z"
   },
   {
    "duration": 256417,
    "start_time": "2023-08-05T10:15:54.398Z"
   },
   {
    "duration": 33000,
    "start_time": "2023-08-05T10:20:10.817Z"
   },
   {
    "duration": 107618,
    "start_time": "2023-08-05T10:20:43.820Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-05T10:22:31.441Z"
   },
   {
    "duration": 59,
    "start_time": "2023-08-05T10:22:31.446Z"
   },
   {
    "duration": 106,
    "start_time": "2023-08-05T10:22:31.507Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
